# T-051: Implement LLM Node and Provider Adapters

**Status:** Pending
**Assigned to:** codex
**Type:** implement
**Phase:** —
**Parent:** —
**Created:** 2026-02-16 06:27 UTC
**Updated:** 2026-02-16 06:27 UTC

## Description

Implement the universal LLM Node backend and provider adapters for OpenAI, Anthropic, Google, Ollama, and Custom endpoints. Support streaming via SSE, structured output, and all configuration options.

## Dependencies

- T-050
- T-042

## Locked Files

- `apps/orchestrator/main.py`
- `apps/orchestrator/models.py`

## Acceptance Criteria

- [ ] LLM Node supports all listed providers
- [ ] Adapters implement the common interface
- [ ] Streaming and structured output work
- [ ] No hardcoded provider logic outside adapters
